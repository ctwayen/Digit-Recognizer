{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 如果不太熟悉CNN，推荐看一下下面链接，可以只看视频，看完后用这个Notebook自己写一个Transfer Learning，和全部的CNN\n",
    "\n",
    "https://www.kaggle.com/learn/deep-learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import section, basic\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'data'\n",
    "test_dir = os.path.join(data_dir, 'test.csv')\n",
    "train_dir = os.path.join(data_dir, 'train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取dataframe data\n",
    "train_df = pd.read_csv(train_dir)\n",
    "test_df = pd.read_csv(test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分离label和images\n",
    "train_Y = train_df['label']\n",
    "train_X = train_df.drop('label',axis=1)\n",
    "train_X = np.reshape(np.array(train_X), (-1, 28, 28))\n",
    "train_X = train_X/255\n",
    "train_X = np.array(\n",
    "    [np.stack((x, x, x), axis=2) for x in train_X]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 28, 28, 3)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x23af12497f0>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 图像没有变，但是增加了三个channel，变味了resnet50接受的rgb格式图片\n",
    "display(train_X.shape)\n",
    "plt.imshow(train_X[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transfer Learning 的意思就是借用了别人train好的weights, 自己再根据这个dataset在最后添加一层prediction layer \n",
    "\n",
    "我用的model可以在这个链接下载，链接里面也给了这个model包含的layers说明\n",
    "https://www.kaggle.com/keras/resnet50#resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.applications import ResNet50\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense\n",
    "\n",
    "weights_path = 'resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    "t_model = Sequential() # 建立我们的transfer model\n",
    "#把别人训练好的weights和model加进去，这里我们把top layer去掉了\n",
    "t_model.add(ResNet50(include_top=False, pooling='avg', weights=weights_path)) \n",
    "t_model.add(Dense(10, activation='softmax'))\n",
    "t_model.layers[0].trainable=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "categorical_crossentropy:https://peltarion.com/knowledge-center/documentation/modeling-view/build-an-ai-model/loss-functions/categorical-crossentropy\n",
    "\n",
    "\n",
    "Adam optimizer\n",
    "https://towardsdatascience.com/adam-latest-trends-in-deep-learning-optimization-6be9a291375c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.losses import categorical_crossentropy\n",
    "train_Y = to_categorical(train_Y, num_classes=10) # one-hot 我们的labels\n",
    "# 虽然前面几层都train好了，我们还是要compile我们的model再fit\n",
    "t_model.compile(loss=categorical_crossentropy, optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Batch size 和 epochs的含义：\n",
    "https://machinelearningmastery.com/difference-between-a-batch-and-an-epoch/\n",
    "\n",
    "简单来说，batch size代表了一次性传进去多少张图片，epochs代表了总共train所有data多少次"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 33600 samples, validate on 8400 samples\n",
      "Epoch 1/2\n",
      "33600/33600 [==============================] - 99s 3ms/sample - loss: 0.5893 - acc: 0.8196 - val_loss: 1.5385 - val_acc: 0.5161\n",
      "Epoch 2/2\n",
      "33600/33600 [==============================] - 99s 3ms/sample - loss: 0.5245 - acc: 0.8368 - val_loss: 0.5386 - val_acc: 0.8383\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x23af1190ef0>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_model.fit(train_X, train_Y, batch_size=100, epochs=2, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到我们的transer learning出来的model第一遍epoch在training data中达到了 81%的accuracy， 在validation data中只有 51%， 第二遍epoch后 validation 也有了83.83，如果想要更加好的数字，我们在合理范围内可以调小batch_size，增大epochs，可以自己都试试，但是最后的结果变化应该不会太大了。Resnet50其实并不是很合适我们的dataset，因为它本来是用在更加复杂的，彩色的图片里，我们用它有些大材小用了，并且也不是很合适。后面的code会自己train一个model，它的accuracy会更加高一些"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scratch CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 重新读取dataframe data 并且resize and one-hot\n",
    "train_df = pd.read_csv(train_dir)\n",
    "test_df = pd.read_csv(test_dir)\n",
    "train_Y = train_df['label']\n",
    "train_X = train_df.drop('label',axis=1)\n",
    "train_X = np.reshape(\n",
    "    np.array(train_X),\n",
    "    (-1, 28, 28, 1)\n",
    ")\n",
    "train_X = train_X/255\n",
    "train_Y = to_categorical(train_Y, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential() # 同样还是Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.layers import Dense, Conv2D, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加入input layer, 因为是input所以要加input_shape\n",
    "model.add(Conv2D(filters=16, \n",
    "                 kernel_size=(5,5),\n",
    "                 activation='relu',\n",
    "                 input_shape=(28, 28, 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conv2D: \n",
    "https://www.saama.com/different-kinds-convolutional-filters/\n",
    "\n",
    "Filters:\n",
    "https://stackoverflow.com/questions/48243360/how-to-determine-the-filter-parameter-in-the-keras-conv2d-function\n",
    "\n",
    "relu:\n",
    "https://medium.com/@danqing/a-practical-guide-to-relu-b83ca804f1f7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加入后续的Conv2D\n",
    "model.add(Conv2D(filters=32, \n",
    "                 kernel_size=(5,5),\n",
    "                 activation='relu',\n",
    "                 input_shape=(28, 28, 1)))\n",
    "model.add(Conv2D(filters=64, \n",
    "                 kernel_size=(5,5),\n",
    "                 activation='relu',\n",
    "                 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加入flatten，把2d变成1d， 紧跟一个dense\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加入softmax最后的预测\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 33600 samples, validate on 8400 samples\n",
      "Epoch 1/4\n",
      "33600/33600 [==============================] - 76s 2ms/sample - loss: 0.1720 - acc: 0.9471 - val_loss: 0.0641 - val_acc: 0.9801\n",
      "Epoch 2/4\n",
      "33600/33600 [==============================] - 77s 2ms/sample - loss: 0.0484 - acc: 0.9848 - val_loss: 0.0444 - val_acc: 0.9875\n",
      "Epoch 3/4\n",
      "33600/33600 [==============================] - 75s 2ms/sample - loss: 0.0314 - acc: 0.9902 - val_loss: 0.0415 - val_acc: 0.9876\n",
      "Epoch 4/4\n",
      "33600/33600 [==============================] - 76s 2ms/sample - loss: 0.0218 - acc: 0.9931 - val_loss: 0.0436 - val_acc: 0.9881\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x23b1a0fe198>"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# comile and fit\n",
    "model.compile(loss=categorical_crossentropy, optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(train_X, train_Y, batch_size=100, epochs=4, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "但是我们如果看高赞notebook里，https://www.kaggle.com/yassineghouzam/introduction-to-cnn-keras-0-997-top-6\n",
    "\n",
    "除开Conv2D，Dense以外还用到了Maxpool， 和Dropout，这两个layer都是用来防止我们的model overfitting，两个layer都很好理解，下面的链接解释他们的作用\n",
    "\n",
    "Maxpool: \n",
    "https://www.quora.com/What-is-max-pooling-in-convolutional-neural-networks\n",
    "\n",
    "Dropout:\n",
    "https://medium.com/@amarbudhiraja/https-medium-com-amarbudhiraja-learning-less-to-learn-better-dropout-in-deep-machine-learning-74334da4bfc5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "自己train的model accuracy比transfer learning高了很多，到最后一个epoch 的validation accuracy已经逼近100%了，但是我们到现在都还没有碰过原数据里面的test data，我们的model很可能存在over fitting。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
